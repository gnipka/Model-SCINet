{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnipka/Model-SCINet/blob/main/%D0%92%D0%9A%D0%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZAoF7_vlnZy"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "la2xeJEfltdM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('sample_data/data_1.csv', parse_dates=['time'], sep=\";\", encoding='cp1251', low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_pA17ZHhndsO"
      },
      "outputs": [],
      "source": [
        "features_considered = ['Defects.Roll10Sqm.DefMap1', \n",
        "                       'OPC_V_voronka_K02', 'OPC_V_shnek_K02',\n",
        "                       'OPC_KN_T_ist_Z1_K02', 'OPC_KN_T_ist_Z2_K02', 'OPC_KN_T_ist_Z3_K02']\n",
        "\n",
        "features = data[features_considered]\n",
        "features.index = data['time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IdODZzMFniyy"
      },
      "outputs": [],
      "source": [
        "features = features.interpolate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m_S5dmxynlCU"
      },
      "outputs": [],
      "source": [
        "features = features[(features.index > '2020-10-21') & (features.index < '2020-10-29')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "wnjQfD7Cnof4",
        "outputId": "f16cbedb-0440-4f9d-986a-7b46fc403cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         OT  OPC_V_voronka_K02  OPC_V_shnek_K02  \\\n",
              "date                                                              \n",
              "2020-10-21 00:00:10  22.034          12.146000            93.36   \n",
              "2020-10-21 00:00:20  21.848          12.122667            94.08   \n",
              "2020-10-21 00:00:30  21.888          12.099333            94.80   \n",
              "2020-10-21 00:00:40  21.751          12.076000            95.52   \n",
              "2020-10-21 00:00:50  21.959          12.074000            95.07   \n",
              "...                     ...                ...              ...   \n",
              "2020-10-28 23:59:12  18.492          16.087333           141.89   \n",
              "2020-10-28 23:59:22  18.503          16.098000           141.75   \n",
              "2020-10-28 23:59:32  18.456          14.804000           130.64   \n",
              "2020-10-28 23:59:42  18.431          13.510000           119.53   \n",
              "2020-10-28 23:59:53  18.351          12.216000           108.42   \n",
              "\n",
              "                     OPC_KN_T_ist_Z1_K02  OPC_KN_T_ist_Z2_K02  \\\n",
              "date                                                            \n",
              "2020-10-21 00:00:10            65.700000           136.100000   \n",
              "2020-10-21 00:00:20            65.700000           136.066667   \n",
              "2020-10-21 00:00:30            65.700000           136.033333   \n",
              "2020-10-21 00:00:40            65.700000           136.000000   \n",
              "2020-10-21 00:00:50            65.700000           136.000000   \n",
              "...                                  ...                  ...   \n",
              "2020-10-28 23:59:12            63.300000           132.366667   \n",
              "2020-10-28 23:59:22            63.300000           132.400000   \n",
              "2020-10-28 23:59:32            63.266667           132.400000   \n",
              "2020-10-28 23:59:42            63.233333           132.400000   \n",
              "2020-10-28 23:59:53            63.200000           132.400000   \n",
              "\n",
              "                     OPC_KN_T_ist_Z3_K02  \n",
              "date                                      \n",
              "2020-10-21 00:00:10           140.600000  \n",
              "2020-10-21 00:00:20           140.600000  \n",
              "2020-10-21 00:00:30           140.600000  \n",
              "2020-10-21 00:00:40           140.600000  \n",
              "2020-10-21 00:00:50           140.600000  \n",
              "...                                  ...  \n",
              "2020-10-28 23:59:12           137.966667  \n",
              "2020-10-28 23:59:22           138.000000  \n",
              "2020-10-28 23:59:32           138.066667  \n",
              "2020-10-28 23:59:42           138.133333  \n",
              "2020-10-28 23:59:53           138.200000  \n",
              "\n",
              "[69328 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c15c4b9-02af-4e57-8d5c-6bf3357a3023\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OT</th>\n",
              "      <th>OPC_V_voronka_K02</th>\n",
              "      <th>OPC_V_shnek_K02</th>\n",
              "      <th>OPC_KN_T_ist_Z1_K02</th>\n",
              "      <th>OPC_KN_T_ist_Z2_K02</th>\n",
              "      <th>OPC_KN_T_ist_Z3_K02</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-10-21 00:00:10</th>\n",
              "      <td>22.034</td>\n",
              "      <td>12.146000</td>\n",
              "      <td>93.36</td>\n",
              "      <td>65.700000</td>\n",
              "      <td>136.100000</td>\n",
              "      <td>140.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-21 00:00:20</th>\n",
              "      <td>21.848</td>\n",
              "      <td>12.122667</td>\n",
              "      <td>94.08</td>\n",
              "      <td>65.700000</td>\n",
              "      <td>136.066667</td>\n",
              "      <td>140.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-21 00:00:30</th>\n",
              "      <td>21.888</td>\n",
              "      <td>12.099333</td>\n",
              "      <td>94.80</td>\n",
              "      <td>65.700000</td>\n",
              "      <td>136.033333</td>\n",
              "      <td>140.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-21 00:00:40</th>\n",
              "      <td>21.751</td>\n",
              "      <td>12.076000</td>\n",
              "      <td>95.52</td>\n",
              "      <td>65.700000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>140.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-21 00:00:50</th>\n",
              "      <td>21.959</td>\n",
              "      <td>12.074000</td>\n",
              "      <td>95.07</td>\n",
              "      <td>65.700000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>140.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-28 23:59:12</th>\n",
              "      <td>18.492</td>\n",
              "      <td>16.087333</td>\n",
              "      <td>141.89</td>\n",
              "      <td>63.300000</td>\n",
              "      <td>132.366667</td>\n",
              "      <td>137.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-28 23:59:22</th>\n",
              "      <td>18.503</td>\n",
              "      <td>16.098000</td>\n",
              "      <td>141.75</td>\n",
              "      <td>63.300000</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>138.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-28 23:59:32</th>\n",
              "      <td>18.456</td>\n",
              "      <td>14.804000</td>\n",
              "      <td>130.64</td>\n",
              "      <td>63.266667</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>138.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-28 23:59:42</th>\n",
              "      <td>18.431</td>\n",
              "      <td>13.510000</td>\n",
              "      <td>119.53</td>\n",
              "      <td>63.233333</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>138.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-28 23:59:53</th>\n",
              "      <td>18.351</td>\n",
              "      <td>12.216000</td>\n",
              "      <td>108.42</td>\n",
              "      <td>63.200000</td>\n",
              "      <td>132.400000</td>\n",
              "      <td>138.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69328 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c15c4b9-02af-4e57-8d5c-6bf3357a3023')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c15c4b9-02af-4e57-8d5c-6bf3357a3023 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c15c4b9-02af-4e57-8d5c-6bf3357a3023');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "features = features.rename(columns={'Defects.Roll10Sqm.DefMap1' : 'OT'})\n",
        "features.index.names = ['date']\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F447XAn5nsYz"
      },
      "outputs": [],
      "source": [
        "features.to_csv('sample_data/data.csv', ',', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G80xvxWT9hB"
      },
      "source": [
        "# Подключение к диску"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhx6zj1qT7Z5",
        "outputId": "33bb07a9-2833-40d8-be94-0dd9928e70d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZA7syl_2UPA2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/SCINet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCudZYbZUUSh"
      },
      "source": [
        "# Подключение необходимых версий библиотек для работы SCINet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RgjtQ1zhUg_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f3129b1-b516-4ac6-9913-9ff0b2ff963f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.4 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.19.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:15:19tcmalloc: large alloc 1147494400 bytes == 0x39872000 @  0x7fcb6fe71615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 92.0 MB/s eta 0:00:11tcmalloc: large alloc 1434370048 bytes == 0x7dec8000 @  0x7fcb6fe71615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:08:45tcmalloc: large alloc 1792966656 bytes == 0x2cfa000 @  0x7fcb6fe71615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:10tcmalloc: large alloc 2241208320 bytes == 0x6dae2000 @  0x7fcb6fe71615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 4.0 MB/s eta 0:00:01tcmalloc: large alloc 1982242816 bytes == 0xf3444000 @  0x7fcb6fe701e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2477809664 bytes == 0x1ddb52000 @  0x7fcb6fe71615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 5.6 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 886 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.19.4\n",
        "!pip install pandas\n",
        "!pip install scikit_learn\n",
        "!pip install tensorboard\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUS_J9xsT2Hr"
      },
      "source": [
        "# Настройка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CnVk_q-Fm6zn"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "from experiments.exp_ETTh import Exp_ETTh\n",
        "\n",
        "def force_cudnn_initialization():\n",
        "    s = 32\n",
        "    dev = torch.device('cuda')\n",
        "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
        "\n",
        "def init_model(args):\n",
        "  torch.manual_seed(4321)  # reproducible\n",
        "  torch.cuda.manual_seed_all(4321)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True  # Can change it to False --> default: False\n",
        "  torch.backends.cudnn.enabled = True\n",
        "\n",
        "  Exp = Exp_ETTh\n",
        "\n",
        "  mae_ = []\n",
        "  maes_ = []\n",
        "  mse_ = []\n",
        "  mses_ = []\n",
        "\n",
        "  force_cudnn_initialization()\n",
        "  if args.evaluate:\n",
        "      setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_lr{}_bs{}_hid{}_s{}_l{}_dp{}_inv{}_itr0'.format(args.model,args.data, args.features, args.seq_len, args.label_len, args.pred_len,args.lr,args.batch_size,args.hidden_size,args.stacks, args.levels,args.dropout,args.inverse)\n",
        "      exp = Exp(args)  # set experiments\n",
        "      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "      mae, maes, mse, mses = exp.test(setting, evaluate=True)\n",
        "      print('Final mean normed mse:{:.4f},mae:{:.4f},denormed mse:{:.4f},mae:{:.4f}'.format(mse, mae, mses, maes))\n",
        "  else:\n",
        "      if args.itr:\n",
        "          for ii in range(args.itr):\n",
        "              # setting record of experiments\n",
        "              setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_lr{}_bs{}_hid{}_s{}_l{}_dp{}_inv{}_itr{}'.format(args.model,args.data, args.features, args.seq_len, args.label_len, args.pred_len,args.lr,args.batch_size,args.hidden_size,args.stacks, args.levels,args.dropout,args.inverse,ii)\n",
        "\n",
        "              exp = Exp(args)  # set experiments\n",
        "              print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "              exp.train(setting)\n",
        "\n",
        "              print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "              mae, maes, mse, mses = exp.test(setting)\n",
        "              mae_.append(mae)\n",
        "              mse_.append(mse)\n",
        "              maes_.append(maes)\n",
        "              mses_.append(mses)\n",
        "\n",
        "              torch.cuda.empty_cache()\n",
        "          print('Final mean normed mse:{:.4f}, std mse:{:.4f}, mae:{:.4f}, std mae:{:.4f}'.format(np.mean(mse_), np.std(mse_), np.mean(mae_),np.std(mae_)))\n",
        "          print('Final mean denormed mse:{:.4f}, std mse:{:.4f}, mae:{:.4f}, std mae:{:.4f}'.format(np.mean(mses_),np.std(mses_), np.mean(maes_), np.std(maes_)))\n",
        "          print('Final min normed mse:{:.4f}, mae:{:.4f}'.format(min(mse_), min(mae_)))\n",
        "          print('Final min denormed mse:{:.4f}, mae:{:.4f}'.format(min(mses_), min(maes_)))\n",
        "      else:\n",
        "          setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_lr{}_bs{}_hid{}_s{}_l{}_dp{}_inv{}_itr0'.format(args.model,args.data, args.features, args.seq_len, args.label_len, args.pred_len,args.lr,args.batch_size,args.hidden_size,args.stacks, args.levels,args.dropout,args.inverse)\n",
        "          exp = Exp(args)  # set experiments\n",
        "          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "          exp.train(setting)\n",
        "\n",
        "          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "          mae, maes, mse, mses = exp.test(setting)\n",
        "          print('Final mean normed mse:{:.4f},mae:{:.4f},denormed mse:{:.4f},mae:{:.4f}'.format(mse, mae, mses, maes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YGJagD5nHDsy"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  \n",
        "  model = 'SCINet'\n",
        "\n",
        "  ### -------  dataset settings --------------\n",
        "  data = 'data'\n",
        "  root_path = 'sample_data/'\n",
        "  data_path = 'data.csv'\n",
        "  features = 'M' # может быть 'S' или 'M'\n",
        "  target = 'OT' # наименование столбца в датасете\n",
        "  freq = 's' # частота для кодирования времени\n",
        "  checkpoints = 'exp/data_checkpoints/' # расположение контрольных точек\n",
        "  inverse = False # денормализация выходных данных\n",
        "  embed = 'timeF' \n",
        "\n",
        "  ### -------  device settings --------------\n",
        "  use_gpu = True # использование gpu\n",
        "  gpu = 0\n",
        "  use_multi_gpu = False \n",
        "  devices = '0'\n",
        "\n",
        "  ### -------  input/output length settings --------------  \n",
        "  seq_len = 96 # look back window, начальная длина SCINet encoder\n",
        "  label_len = 48 # начальная длина Informer decoder\n",
        "  pred_len = 48 # длина поледовательности прогнозирования\n",
        "  concat_len = 0\n",
        "  single_step = 0\n",
        "  single_step_output_One = 0\n",
        "  lastWeight = 1.0\n",
        "\n",
        "  ### -------  training settings --------------  \n",
        "  cols = \"\"\n",
        "  num_workers = 0 # количество работников-загрузчиков данных ??\n",
        "  itr = 0\n",
        "  train_epochs = 100 # количество эпох для тренировки\n",
        "  batch_size = 32\n",
        "  patience = 5\n",
        "  lr = 0.0001\n",
        "  loss = \"mae\" # оценочная функция\n",
        "  lradj = 1\n",
        "  use_amp = False\n",
        "  save = True # сохранение выходных результатов\n",
        "  model_name = 'SCINet'\n",
        "  resume = False\n",
        "  evaluate = False\n",
        "\n",
        "  ### -------  model settings --------------  \n",
        "  hidden_size = 1\n",
        "  INN = 1\n",
        "  kernel = 5 # 3,5,7\n",
        "  dilation = 1\n",
        "  window_size = 12\n",
        "  dropout = 0.5\n",
        "  positionalEcoding = False\n",
        "  groups = 1\n",
        "  levels = 3\n",
        "  stacks = 1\n",
        "  num_decoder_layer = 1\n",
        "  RIN = False\n",
        "  decompose = False\n",
        "  def __init__(self, data, features, seq_len, label_len, pred_len, hidden_size, stacks, levels, lr, batch_size, dropout, model_name):\n",
        "    self.data = data\n",
        "    self.features = features\n",
        "    self.seq_len = seq_len\n",
        "    self.label_len = label_len\n",
        "    self.pred_len = pred_len\n",
        "    self.hidden_size = hidden_size\n",
        "    self.stacks = stacks\n",
        "    self.levels = levels\n",
        "    self.lr = lr\n",
        "    self.batch_size = batch_size\n",
        "    self.dropout = dropout\n",
        "    self.model_name = model_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPdPSiWPtKqi"
      },
      "source": [
        "*   количество уровней SCINet блока - 3\n",
        "*   количество SCINet блоков - 1\n",
        "*   размер скользящего окна - 168"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXLhoh-8sBf9",
        "outputId": "61a7d33f-3107-4a73-9a0b-58c6af2dd505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCINet(\n",
            "  (blocks1): EncoderTree(\n",
            "    (SCINet_Tree): SCINet_Tree(\n",
            "      (workingblock): LevelSCINet(\n",
            "        (interact): InteractorLevel(\n",
            "          (level): Interactor(\n",
            "            (split): Splitting()\n",
            "            (phi): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.25, inplace=False)\n",
            "              (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (psi): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.25, inplace=False)\n",
            "              (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (P): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.25, inplace=False)\n",
            "              (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (U): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.25, inplace=False)\n",
            "              (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (SCINet_Tree_odd): SCINet_Tree(\n",
            "        (workingblock): LevelSCINet(\n",
            "          (interact): InteractorLevel(\n",
            "            (level): Interactor(\n",
            "              (split): Splitting()\n",
            "              (phi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (psi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (P): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (U): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_odd): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_even): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (SCINet_Tree_even): SCINet_Tree(\n",
            "        (workingblock): LevelSCINet(\n",
            "          (interact): InteractorLevel(\n",
            "            (level): Interactor(\n",
            "              (split): Splitting()\n",
            "              (phi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (psi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (P): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (U): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.25, inplace=False)\n",
            "                (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_odd): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_even): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 8, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.25, inplace=False)\n",
            "                  (4): Conv1d(8, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (projection1): Conv1d(64, 24, kernel_size=(1,), stride=(1,), bias=False)\n",
            "  (div_projection): ModuleList()\n",
            ")\n",
            ">>>>>>>start training : SCINet_data_ftS_sl64_ll24_pl24_lr0.007_bs64_hid8_s1_l3_dp0.25_invFalse_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 48442\n",
            "val 6911\n",
            "test 13842\n",
            "exp/data_checkpoints/SCINet_data_ftS_sl64_ll24_pl24_lr0.007_bs64_hid8_s1_l3_dp0.25_invFalse_itr0\n",
            "\titers: 100, epoch: 1 | loss: 0.0373032\n",
            "\tspeed: 0.0416s/iter; left time: 3138.9798s\n",
            "\titers: 200, epoch: 1 | loss: 0.0317414\n",
            "\tspeed: 0.0418s/iter; left time: 3154.9474s\n",
            "\titers: 300, epoch: 1 | loss: 0.0355631\n",
            "\tspeed: 0.0411s/iter; left time: 3096.5845s\n",
            "\titers: 400, epoch: 1 | loss: 0.0368229\n",
            "\tspeed: 0.0411s/iter; left time: 3089.4108s\n",
            "\titers: 500, epoch: 1 | loss: 0.0651039\n",
            "\tspeed: 0.0413s/iter; left time: 3098.4953s\n",
            "\titers: 600, epoch: 1 | loss: 0.0201411\n",
            "\tspeed: 0.0413s/iter; left time: 3097.4130s\n",
            "\titers: 700, epoch: 1 | loss: 0.0550040\n",
            "\tspeed: 0.0416s/iter; left time: 3114.5545s\n",
            "Epoch: 1 cost time: 31.345473051071167\n",
            "--------start to validate-----------\n",
            "normed mse:0.0239, mae:0.0544, rmse:0.1545, mape:1.6460, mspe:3529.7668, corr:0.8973\n",
            "denormed mse:18.8532, mae:1.5295, rmse:4.3420, mape:inf, mspe:inf, corr:0.8973\n",
            "--------start to test-----------\n",
            "normed mse:0.8043, mae:0.1313, rmse:0.8968, mape:0.2654, mspe:5.4201, corr:0.7603\n",
            "denormed mse:635.1712, mae:3.6899, rmse:25.2026, mape:inf, mspe:inf, corr:0.7603\n",
            "Epoch: 1, Steps: 756 | Train Loss: 0.0644833 valid Loss: 0.0544246 Test Loss: 0.1313030\n",
            "Validation loss decreased (inf --> 0.054425).  Saving model ...\n",
            "Updating learning rate to 0.00665\n",
            "\titers: 100, epoch: 2 | loss: 0.0309053\n",
            "\tspeed: 0.1055s/iter; left time: 7884.3931s\n",
            "\titers: 200, epoch: 2 | loss: 0.0861472\n",
            "\tspeed: 0.0415s/iter; left time: 3099.6393s\n",
            "\titers: 300, epoch: 2 | loss: 0.0578696\n",
            "\tspeed: 0.0418s/iter; left time: 3113.8024s\n",
            "\titers: 400, epoch: 2 | loss: 0.0482651\n",
            "\tspeed: 0.0416s/iter; left time: 3097.3079s\n",
            "\titers: 500, epoch: 2 | loss: 0.0283688\n",
            "\tspeed: 0.0418s/iter; left time: 3111.0911s\n",
            "\titers: 600, epoch: 2 | loss: 0.1880503\n",
            "\tspeed: 0.0415s/iter; left time: 3082.8347s\n",
            "\titers: 700, epoch: 2 | loss: 0.0274356\n",
            "\tspeed: 0.0417s/iter; left time: 3093.3378s\n",
            "Epoch: 2 cost time: 31.48236083984375\n",
            "--------start to validate-----------\n",
            "normed mse:0.0218, mae:0.0447, rmse:0.1477, mape:1.6456, mspe:4326.8737, corr:0.9056\n",
            "denormed mse:17.2368, mae:1.2575, rmse:4.1517, mape:inf, mspe:inf, corr:0.9056\n",
            "--------start to test-----------\n",
            "normed mse:0.7946, mae:0.1227, rmse:0.8914, mape:0.2388, mspe:4.8187, corr:0.7654\n",
            "denormed mse:627.5178, mae:3.4484, rmse:25.0503, mape:inf, mspe:inf, corr:0.7654\n",
            "Epoch: 2, Steps: 756 | Train Loss: 0.0576795 valid Loss: 0.0447460 Test Loss: 0.1227074\n",
            "Validation loss decreased (0.054425 --> 0.044746).  Saving model ...\n",
            "Updating learning rate to 0.0063175\n",
            "\titers: 100, epoch: 3 | loss: 0.0413894\n",
            "\tspeed: 0.1060s/iter; left time: 7841.9999s\n",
            "\titers: 200, epoch: 3 | loss: 0.0362729\n",
            "\tspeed: 0.0411s/iter; left time: 3039.3855s\n",
            "\titers: 300, epoch: 3 | loss: 0.0322017\n",
            "\tspeed: 0.0415s/iter; left time: 3065.6249s\n",
            "\titers: 400, epoch: 3 | loss: 0.0654635\n",
            "\tspeed: 0.0420s/iter; left time: 3095.4565s\n",
            "\titers: 500, epoch: 3 | loss: 0.0296324\n",
            "\tspeed: 0.0417s/iter; left time: 3068.9859s\n",
            "\titers: 600, epoch: 3 | loss: 0.0330478\n",
            "\tspeed: 0.0415s/iter; left time: 3050.4068s\n",
            "\titers: 700, epoch: 3 | loss: 0.0220298\n",
            "\tspeed: 0.0413s/iter; left time: 3032.2902s\n",
            "Epoch: 3 cost time: 32.34422016143799\n",
            "--------start to validate-----------\n",
            "normed mse:0.0225, mae:0.0472, rmse:0.1501, mape:1.5400, mspe:4048.5943, corr:0.9035\n",
            "denormed mse:17.7990, mae:1.3271, rmse:4.2189, mape:inf, mspe:inf, corr:0.9035\n",
            "--------start to test-----------\n",
            "normed mse:0.8587, mae:0.1221, rmse:0.9267, mape:0.2430, mspe:5.5408, corr:0.7447\n",
            "denormed mse:678.1625, mae:3.4327, rmse:26.0416, mape:inf, mspe:inf, corr:0.7447\n",
            "Epoch: 3, Steps: 756 | Train Loss: 0.0544092 valid Loss: 0.0472234 Test Loss: 0.1221484\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 0.006001624999999999\n",
            "\titers: 100, epoch: 4 | loss: 0.1168233\n",
            "\tspeed: 0.1209s/iter; left time: 8855.1336s\n",
            "\titers: 200, epoch: 4 | loss: 0.0324668\n",
            "\tspeed: 0.0416s/iter; left time: 3045.7411s\n",
            "\titers: 300, epoch: 4 | loss: 0.1188834\n",
            "\tspeed: 0.0417s/iter; left time: 3043.7736s\n",
            "\titers: 400, epoch: 4 | loss: 0.0219905\n",
            "\tspeed: 0.0416s/iter; left time: 3031.3112s\n",
            "\titers: 500, epoch: 4 | loss: 0.0190656\n",
            "\tspeed: 0.0416s/iter; left time: 3028.4486s\n",
            "\titers: 600, epoch: 4 | loss: 0.1351711\n",
            "\tspeed: 0.0412s/iter; left time: 2997.6159s\n",
            "\titers: 700, epoch: 4 | loss: 0.0347938\n",
            "\tspeed: 0.0415s/iter; left time: 3010.9670s\n",
            "Epoch: 4 cost time: 31.410381078720093\n",
            "--------start to validate-----------\n",
            "normed mse:0.0225, mae:0.0453, rmse:0.1499, mape:1.5380, mspe:4110.8127, corr:0.9035\n",
            "denormed mse:17.7396, mae:1.2730, rmse:4.2118, mape:inf, mspe:inf, corr:0.9035\n",
            "--------start to test-----------\n",
            "normed mse:0.8213, mae:0.1194, rmse:0.9063, mape:0.2403, mspe:5.8520, corr:0.7617\n",
            "denormed mse:648.6193, mae:3.3551, rmse:25.4680, mape:inf, mspe:inf, corr:0.7617\n",
            "Epoch: 4, Steps: 756 | Train Loss: 0.0534553 valid Loss: 0.0452980 Test Loss: 0.1193890\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Updating learning rate to 0.0057015437499999995\n",
            "\titers: 100, epoch: 5 | loss: 0.0256203\n",
            "\tspeed: 0.1066s/iter; left time: 7722.9429s\n",
            "\titers: 200, epoch: 5 | loss: 0.0219104\n",
            "\tspeed: 0.0423s/iter; left time: 3062.2603s\n",
            "\titers: 300, epoch: 5 | loss: 0.0378755\n",
            "\tspeed: 0.0422s/iter; left time: 3049.4074s\n",
            "\titers: 400, epoch: 5 | loss: 0.0435321\n",
            "\tspeed: 0.0416s/iter; left time: 3000.7275s\n",
            "\titers: 500, epoch: 5 | loss: 0.0326093\n",
            "\tspeed: 0.0416s/iter; left time: 2998.6093s\n",
            "\titers: 600, epoch: 5 | loss: 0.3279118\n",
            "\tspeed: 0.0416s/iter; left time: 2993.5119s\n",
            "\titers: 700, epoch: 5 | loss: 0.0191800\n",
            "\tspeed: 0.0410s/iter; left time: 2948.0012s\n",
            "Epoch: 5 cost time: 31.586596488952637\n",
            "--------start to validate-----------\n",
            "normed mse:0.0259, mae:0.0470, rmse:0.1608, mape:1.6565, mspe:3114.0873, corr:0.8966\n",
            "denormed mse:20.4270, mae:1.3213, rmse:4.5196, mape:inf, mspe:inf, corr:0.8966\n",
            "--------start to test-----------\n",
            "normed mse:0.9101, mae:0.1386, rmse:0.9540, mape:0.2724, mspe:7.3612, corr:0.7661\n",
            "denormed mse:718.7729, mae:3.8959, rmse:26.8099, mape:inf, mspe:inf, corr:0.7661\n",
            "Epoch: 5, Steps: 756 | Train Loss: 0.0530397 valid Loss: 0.0470166 Test Loss: 0.1386316\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Updating learning rate to 0.005416466562499999\n",
            "\titers: 100, epoch: 6 | loss: 0.0332494\n",
            "\tspeed: 0.1056s/iter; left time: 7574.7914s\n",
            "\titers: 200, epoch: 6 | loss: 0.0307287\n",
            "\tspeed: 0.0417s/iter; left time: 2987.6287s\n",
            "\titers: 300, epoch: 6 | loss: 0.0180029\n",
            "\tspeed: 0.0414s/iter; left time: 2960.8201s\n",
            "\titers: 400, epoch: 6 | loss: 0.2195445\n",
            "\tspeed: 0.0409s/iter; left time: 2922.8840s\n",
            "\titers: 500, epoch: 6 | loss: 0.0491448\n",
            "\tspeed: 0.0413s/iter; left time: 2942.7641s\n",
            "\titers: 600, epoch: 6 | loss: 0.0335671\n",
            "\tspeed: 0.0412s/iter; left time: 2936.7965s\n",
            "\titers: 700, epoch: 6 | loss: 0.0421473\n",
            "\tspeed: 0.0417s/iter; left time: 2967.6622s\n",
            "Epoch: 6 cost time: 31.286328554153442\n",
            "--------start to validate-----------\n",
            "normed mse:0.0234, mae:0.0487, rmse:0.1530, mape:1.4621, mspe:2096.4237, corr:0.9023\n",
            "denormed mse:18.4884, mae:1.3694, rmse:4.2998, mape:inf, mspe:inf, corr:0.9023\n",
            "--------start to test-----------\n",
            "normed mse:3.3058, mae:0.1733, rmse:1.8182, mape:0.2806, mspe:4.0777, corr:0.5138\n",
            "denormed mse:2610.7157, mae:4.8714, rmse:51.0952, mape:inf, mspe:inf, corr:0.5138\n",
            "Epoch: 6, Steps: 756 | Train Loss: 0.0515970 valid Loss: 0.0487281 Test Loss: 0.1733446\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Updating learning rate to 0.005145643234374999\n",
            "\titers: 100, epoch: 7 | loss: 0.0337101\n",
            "\tspeed: 0.1066s/iter; left time: 7565.8661s\n",
            "\titers: 200, epoch: 7 | loss: 0.0389403\n",
            "\tspeed: 0.0415s/iter; left time: 2943.5015s\n",
            "\titers: 300, epoch: 7 | loss: 0.0224441\n",
            "\tspeed: 0.0415s/iter; left time: 2934.9899s\n",
            "\titers: 400, epoch: 7 | loss: 0.0258481\n",
            "\tspeed: 0.0420s/iter; left time: 2969.8022s\n",
            "\titers: 500, epoch: 7 | loss: 0.1820620\n",
            "\tspeed: 0.0416s/iter; left time: 2938.8670s\n",
            "\titers: 600, epoch: 7 | loss: 0.0349627\n",
            "\tspeed: 0.0418s/iter; left time: 2945.3141s\n",
            "\titers: 700, epoch: 7 | loss: 0.3022019\n",
            "\tspeed: 0.0414s/iter; left time: 2914.6897s\n",
            "Epoch: 7 cost time: 31.508919954299927\n",
            "--------start to validate-----------\n",
            "normed mse:0.0270, mae:0.0539, rmse:0.1642, mape:1.6690, mspe:1868.3373, corr:0.8839\n",
            "denormed mse:21.3024, mae:1.5147, rmse:4.6155, mape:inf, mspe:inf, corr:0.8839\n",
            "--------start to test-----------\n",
            "normed mse:1.1154, mae:0.1933, rmse:1.0561, mape:0.3191, mspe:4.3289, corr:0.6744\n",
            "denormed mse:880.8879, mae:5.4332, rmse:29.6798, mape:inf, mspe:inf, corr:0.6744\n",
            "Epoch: 7, Steps: 756 | Train Loss: 0.0490415 valid Loss: 0.0539009 Test Loss: 0.1933372\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "save model in  exp/data_checkpoints/SCINet_data_ftS_sl64_ll24_pl24_lr0.007_bs64_hid8_s1_l3_dp0.25_invFalse_itr0/data24.bin\n",
            ">>>>>>>testing : SCINet_data_ftS_sl64_ll24_pl24_lr0.007_bs64_hid8_s1_l3_dp0.25_invFalse_itr0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 13842\n",
            "normed mse:0.7946, mae:0.1227, rmse:0.8914, mape:0.2388, mspe:4.8187, corr:0.7654\n",
            "TTTT denormed mse:627.5178, mae:3.4484, rmse:25.0503, mape:inf, mspe:inf, corr:0.7654\n",
            "Test:mse:0.7946, mae:0.1227, rmse:0.8914, mape:0.2388, mspe:4.8187, corr:0.7654\n",
            "Final mean normed mse:0.7946,mae:0.1227,denormed mse:627.5178,mae:3.4484\n"
          ]
        }
      ],
      "source": [
        "args = Args('data', 'S', 64, 24, 24, 8, 1, 3, 0.007, 64, 0.25, 'data_M_I48_O24_lr3e-3_bs8_dp0.5_h4_s1l3')\n",
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]\n",
        "\n",
        "init_model(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "76WRkUoUtgtg",
        "outputId": "c4a5030b-9a51-4469-b5d0-9221c7504282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCINet(\n",
            "  (blocks1): EncoderTree(\n",
            "    (SCINet_Tree): SCINet_Tree(\n",
            "      (workingblock): LevelSCINet(\n",
            "        (interact): InteractorLevel(\n",
            "          (level): Interactor(\n",
            "            (split): Splitting()\n",
            "            (phi): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.5, inplace=False)\n",
            "              (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (psi): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.5, inplace=False)\n",
            "              (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (P): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.5, inplace=False)\n",
            "              (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "            (U): Sequential(\n",
            "              (0): ReplicationPad1d((3, 3))\n",
            "              (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (3): Dropout(p=0.5, inplace=False)\n",
            "              (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "              (5): Tanh()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (SCINet_Tree_odd): SCINet_Tree(\n",
            "        (workingblock): LevelSCINet(\n",
            "          (interact): InteractorLevel(\n",
            "            (level): Interactor(\n",
            "              (split): Splitting()\n",
            "              (phi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (psi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (P): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (U): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_odd): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_odd): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_even): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_even): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_odd): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_even): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (SCINet_Tree_even): SCINet_Tree(\n",
            "        (workingblock): LevelSCINet(\n",
            "          (interact): InteractorLevel(\n",
            "            (level): Interactor(\n",
            "              (split): Splitting()\n",
            "              (phi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (psi): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (P): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "              (U): Sequential(\n",
            "                (0): ReplicationPad1d((3, 3))\n",
            "                (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                (3): Dropout(p=0.5, inplace=False)\n",
            "                (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                (5): Tanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_odd): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_odd): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_even): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (SCINet_Tree_even): SCINet_Tree(\n",
            "          (workingblock): LevelSCINet(\n",
            "            (interact): InteractorLevel(\n",
            "              (level): Interactor(\n",
            "                (split): Splitting()\n",
            "                (phi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (P): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "                (U): Sequential(\n",
            "                  (0): ReplicationPad1d((3, 3))\n",
            "                  (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                  (3): Dropout(p=0.5, inplace=False)\n",
            "                  (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                  (5): Tanh()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_odd): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (SCINet_Tree_even): SCINet_Tree(\n",
            "            (workingblock): LevelSCINet(\n",
            "              (interact): InteractorLevel(\n",
            "                (level): Interactor(\n",
            "                  (split): Splitting()\n",
            "                  (phi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (psi): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (P): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                  (U): Sequential(\n",
            "                    (0): ReplicationPad1d((3, 3))\n",
            "                    (1): Conv1d(1, 4, kernel_size=(5,), stride=(1,))\n",
            "                    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "                    (3): Dropout(p=0.5, inplace=False)\n",
            "                    (4): Conv1d(4, 1, kernel_size=(3,), stride=(1,))\n",
            "                    (5): Tanh()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (projection1): Conv1d(720, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
            "  (div_projection): ModuleList()\n",
            ")\n",
            ">>>>>>>start training : SCINet_data_ftS_sl720_ll48_pl48_lr0.0001_bs8_hid4_s1_l4_dp0.5_invFalse_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 47762\n",
            "val 6887\n",
            "test 13818\n",
            "exp/data_checkpoints/SCINet_data_ftS_sl720_ll48_pl48_lr0.0001_bs8_hid4_s1_l4_dp0.5_invFalse_itr0\n",
            "\titers: 100, epoch: 1 | loss: 0.1204913\n",
            "\tspeed: 0.1870s/iter; left time: 111618.8436s\n",
            "\titers: 200, epoch: 1 | loss: 0.2738267\n",
            "\tspeed: 0.1901s/iter; left time: 113430.3233s\n",
            "\titers: 300, epoch: 1 | loss: 0.2353543\n",
            "\tspeed: 0.1910s/iter; left time: 113947.5535s\n",
            "\titers: 400, epoch: 1 | loss: 0.1428741\n",
            "\tspeed: 0.1909s/iter; left time: 113862.8501s\n",
            "\titers: 500, epoch: 1 | loss: 0.0903991\n",
            "\tspeed: 0.1883s/iter; left time: 112312.6247s\n",
            "\titers: 600, epoch: 1 | loss: 0.1043828\n",
            "\tspeed: 0.1899s/iter; left time: 113250.6660s\n",
            "\titers: 700, epoch: 1 | loss: 0.0782276\n",
            "\tspeed: 0.1932s/iter; left time: 115182.0115s\n",
            "\titers: 800, epoch: 1 | loss: 0.0810785\n",
            "\tspeed: 0.1961s/iter; left time: 116941.4431s\n",
            "\titers: 900, epoch: 1 | loss: 0.1173683\n",
            "\tspeed: 0.1957s/iter; left time: 116680.7380s\n",
            "\titers: 1000, epoch: 1 | loss: 0.1096581\n",
            "\tspeed: 0.1949s/iter; left time: 116169.2729s\n",
            "\titers: 1100, epoch: 1 | loss: 0.1295897\n",
            "\tspeed: 0.2077s/iter; left time: 123743.3428s\n",
            "\titers: 1200, epoch: 1 | loss: 1.9564119\n",
            "\tspeed: 0.1928s/iter; left time: 114844.9361s\n",
            "\titers: 1300, epoch: 1 | loss: 0.0671742\n",
            "\tspeed: 0.1949s/iter; left time: 116102.5979s\n",
            "\titers: 1400, epoch: 1 | loss: 0.1103213\n",
            "\tspeed: 0.1921s/iter; left time: 114410.7846s\n",
            "\titers: 1500, epoch: 1 | loss: 0.0917779\n",
            "\tspeed: 0.1941s/iter; left time: 115572.3111s\n",
            "\titers: 1600, epoch: 1 | loss: 0.0691651\n",
            "\tspeed: 0.1943s/iter; left time: 115700.2936s\n",
            "\titers: 1700, epoch: 1 | loss: 0.0642799\n",
            "\tspeed: 0.1924s/iter; left time: 114541.0716s\n",
            "\titers: 1800, epoch: 1 | loss: 0.7754540\n",
            "\tspeed: 0.1936s/iter; left time: 115238.1261s\n",
            "\titers: 1900, epoch: 1 | loss: 0.0409195\n",
            "\tspeed: 0.1953s/iter; left time: 116223.8423s\n",
            "\titers: 2000, epoch: 1 | loss: 0.0699537\n",
            "\tspeed: 0.1934s/iter; left time: 115056.8152s\n",
            "\titers: 2100, epoch: 1 | loss: 0.0516992\n",
            "\tspeed: 0.1945s/iter; left time: 115710.8475s\n",
            "\titers: 2200, epoch: 1 | loss: 0.1103710\n",
            "\tspeed: 0.1959s/iter; left time: 116504.3945s\n",
            "\titers: 2300, epoch: 1 | loss: 0.0496769\n",
            "\tspeed: 0.2092s/iter; left time: 124407.9659s\n",
            "\titers: 2400, epoch: 1 | loss: 0.0701383\n",
            "\tspeed: 0.1944s/iter; left time: 115570.8004s\n",
            "\titers: 2500, epoch: 1 | loss: 0.0585403\n",
            "\tspeed: 0.1966s/iter; left time: 116867.2730s\n",
            "\titers: 2600, epoch: 1 | loss: 0.0723326\n",
            "\tspeed: 0.1946s/iter; left time: 115679.7782s\n",
            "\titers: 2700, epoch: 1 | loss: 0.0611722\n",
            "\tspeed: 0.1922s/iter; left time: 114214.9606s\n",
            "\titers: 2800, epoch: 1 | loss: 0.0524108\n",
            "\tspeed: 0.1910s/iter; left time: 113486.1924s\n",
            "\titers: 2900, epoch: 1 | loss: 0.9808592\n",
            "\tspeed: 0.1900s/iter; left time: 112851.6613s\n",
            "\titers: 3000, epoch: 1 | loss: 0.0848860\n",
            "\tspeed: 0.1868s/iter; left time: 110987.1945s\n",
            "\titers: 3100, epoch: 1 | loss: 1.2700282\n",
            "\tspeed: 0.1889s/iter; left time: 112182.2130s\n",
            "\titers: 3200, epoch: 1 | loss: 0.1415012\n",
            "\tspeed: 0.1879s/iter; left time: 111590.0318s\n",
            "\titers: 3300, epoch: 1 | loss: 0.0428521\n",
            "\tspeed: 0.1872s/iter; left time: 111120.7939s\n",
            "\titers: 3400, epoch: 1 | loss: 0.0507086\n",
            "\tspeed: 0.1869s/iter; left time: 110953.3524s\n",
            "\titers: 3500, epoch: 1 | loss: 0.0484255\n",
            "\tspeed: 0.1873s/iter; left time: 111133.3518s\n",
            "\titers: 3600, epoch: 1 | loss: 0.0424990\n",
            "\tspeed: 0.2020s/iter; left time: 119875.6848s\n",
            "\titers: 3700, epoch: 1 | loss: 0.0409326\n",
            "\tspeed: 0.1872s/iter; left time: 111044.0163s\n",
            "\titers: 3800, epoch: 1 | loss: 0.0461680\n",
            "\tspeed: 0.1903s/iter; left time: 112891.0988s\n",
            "\titers: 3900, epoch: 1 | loss: 0.0370337\n",
            "\tspeed: 0.1876s/iter; left time: 111257.1048s\n",
            "\titers: 4000, epoch: 1 | loss: 0.0440205\n",
            "\tspeed: 0.1899s/iter; left time: 112616.3021s\n",
            "\titers: 4100, epoch: 1 | loss: 0.0455448\n",
            "\tspeed: 0.1875s/iter; left time: 111176.5101s\n",
            "\titers: 4200, epoch: 1 | loss: 0.0414077\n",
            "\tspeed: 0.1866s/iter; left time: 110638.8977s\n",
            "\titers: 4300, epoch: 1 | loss: 0.0290648\n",
            "\tspeed: 0.1867s/iter; left time: 110634.5925s\n",
            "\titers: 4400, epoch: 1 | loss: 0.0662371\n",
            "\tspeed: 0.1881s/iter; left time: 111445.9301s\n",
            "\titers: 4500, epoch: 1 | loss: 0.0839377\n",
            "\tspeed: 0.1875s/iter; left time: 111115.4929s\n",
            "\titers: 4600, epoch: 1 | loss: 0.0544652\n",
            "\tspeed: 0.1851s/iter; left time: 109667.8978s\n",
            "\titers: 4700, epoch: 1 | loss: 0.8011264\n",
            "\tspeed: 0.1863s/iter; left time: 110341.8077s\n",
            "\titers: 4800, epoch: 1 | loss: 0.5380983\n",
            "\tspeed: 0.1856s/iter; left time: 109923.0537s\n",
            "\titers: 4900, epoch: 1 | loss: 0.3596354\n",
            "\tspeed: 0.2009s/iter; left time: 118964.9612s\n",
            "\titers: 5000, epoch: 1 | loss: 0.0667038\n",
            "\tspeed: 0.1863s/iter; left time: 110266.4897s\n",
            "\titers: 5100, epoch: 1 | loss: 1.3243433\n",
            "\tspeed: 0.1863s/iter; left time: 110265.1283s\n",
            "\titers: 5200, epoch: 1 | loss: 0.0609385\n",
            "\tspeed: 0.1861s/iter; left time: 110131.1037s\n",
            "\titers: 5300, epoch: 1 | loss: 0.0676572\n",
            "\tspeed: 0.1874s/iter; left time: 110904.9606s\n",
            "\titers: 5400, epoch: 1 | loss: 0.0348218\n",
            "\tspeed: 0.1870s/iter; left time: 110608.8393s\n",
            "\titers: 5500, epoch: 1 | loss: 0.0371414\n",
            "\tspeed: 0.1877s/iter; left time: 111003.5796s\n",
            "\titers: 5600, epoch: 1 | loss: 0.4654137\n",
            "\tspeed: 0.1860s/iter; left time: 110007.0757s\n",
            "\titers: 5700, epoch: 1 | loss: 0.0535892\n",
            "\tspeed: 0.1882s/iter; left time: 111276.1937s\n",
            "\titers: 5800, epoch: 1 | loss: 0.0658446\n",
            "\tspeed: 0.1862s/iter; left time: 110094.1746s\n",
            "\titers: 5900, epoch: 1 | loss: 0.0458787\n",
            "\tspeed: 0.1859s/iter; left time: 109874.9803s\n",
            "Epoch: 1 cost time: 1140.1654262542725\n",
            "--------start to validate-----------\n",
            "normed mse:0.0517, mae:0.0924, rmse:0.2274, mape:4.6903, mspe:27488.0809, corr:0.7508\n",
            "denormed mse:40.8335, mae:2.5962, rmse:6.3901, mape:inf, mspe:inf, corr:0.7508\n",
            "--------start to test-----------\n",
            "normed mse:1.2870, mae:0.2134, rmse:1.1345, mape:0.4585, mspe:7.5542, corr:0.5717\n",
            "denormed mse:1016.4244, mae:5.9979, rmse:31.8814, mape:inf, mspe:inf, corr:0.5717\n",
            "Epoch: 1, Steps: 5970 | Train Loss: 0.2069974 valid Loss: 0.0923845 Test Loss: 0.2134299\n",
            "Validation loss decreased (inf --> 0.092384).  Saving model ...\n",
            "Updating learning rate to 9.5e-05\n",
            "\titers: 100, epoch: 2 | loss: 0.0880320\n",
            "\tspeed: 1.4148s/iter; left time: 836046.6655s\n",
            "\titers: 200, epoch: 2 | loss: 0.0341721\n",
            "\tspeed: 0.1899s/iter; left time: 112213.1963s\n",
            "\titers: 300, epoch: 2 | loss: 0.3366773\n",
            "\tspeed: 0.1941s/iter; left time: 114651.4921s\n",
            "\titers: 400, epoch: 2 | loss: 0.0639082\n",
            "\tspeed: 0.1958s/iter; left time: 115672.8707s\n",
            "\titers: 500, epoch: 2 | loss: 0.0324719\n",
            "\tspeed: 0.1928s/iter; left time: 113883.0295s\n",
            "\titers: 600, epoch: 2 | loss: 0.0560060\n",
            "\tspeed: 0.1932s/iter; left time: 114063.0310s\n",
            "\titers: 700, epoch: 2 | loss: 0.2168448\n",
            "\tspeed: 0.1916s/iter; left time: 113131.7917s\n",
            "\titers: 800, epoch: 2 | loss: 0.0295126\n",
            "\tspeed: 0.1917s/iter; left time: 113173.1099s\n",
            "\titers: 900, epoch: 2 | loss: 0.0486275\n",
            "\tspeed: 0.1933s/iter; left time: 114052.7845s\n",
            "\titers: 1000, epoch: 2 | loss: 0.0259619\n",
            "\tspeed: 0.1971s/iter; left time: 116315.7290s\n",
            "\titers: 1100, epoch: 2 | loss: 0.4027206\n",
            "\tspeed: 0.1969s/iter; left time: 116173.9477s\n",
            "\titers: 1200, epoch: 2 | loss: 0.0476722\n",
            "\tspeed: 0.2090s/iter; left time: 123296.0717s\n",
            "\titers: 1300, epoch: 2 | loss: 0.0399821\n",
            "\tspeed: 0.2020s/iter; left time: 119112.0730s\n",
            "\titers: 1400, epoch: 2 | loss: 0.1192212\n",
            "\tspeed: 0.1964s/iter; left time: 115794.0442s\n",
            "\titers: 1500, epoch: 2 | loss: 0.0309895\n",
            "\tspeed: 0.1939s/iter; left time: 114309.5893s\n",
            "\titers: 1600, epoch: 2 | loss: 0.0355875\n",
            "\tspeed: 0.1946s/iter; left time: 114711.8930s\n",
            "\titers: 1700, epoch: 2 | loss: 0.0348610\n",
            "\tspeed: 0.1952s/iter; left time: 115064.1679s\n",
            "\titers: 1800, epoch: 2 | loss: 0.0447116\n",
            "\tspeed: 0.1952s/iter; left time: 114999.2011s\n",
            "\titers: 1900, epoch: 2 | loss: 0.4302282\n",
            "\tspeed: 0.1929s/iter; left time: 113649.3870s\n",
            "\titers: 2000, epoch: 2 | loss: 0.0416238\n",
            "\tspeed: 0.1925s/iter; left time: 113362.3113s\n",
            "\titers: 2100, epoch: 2 | loss: 0.0386015\n",
            "\tspeed: 0.1932s/iter; left time: 113799.2787s\n",
            "\titers: 2200, epoch: 2 | loss: 0.0966682\n",
            "\tspeed: 0.1930s/iter; left time: 113615.4459s\n",
            "\titers: 2300, epoch: 2 | loss: 0.0351684\n",
            "\tspeed: 0.1908s/iter; left time: 112356.4060s\n",
            "\titers: 2400, epoch: 2 | loss: 0.0609934\n",
            "\tspeed: 0.1928s/iter; left time: 113475.2155s\n",
            "\titers: 2500, epoch: 2 | loss: 0.0447632\n",
            "\tspeed: 0.1925s/iter; left time: 113308.4704s\n",
            "\titers: 2600, epoch: 2 | loss: 0.3304456\n",
            "\tspeed: 0.1934s/iter; left time: 113830.2235s\n",
            "\titers: 2700, epoch: 2 | loss: 0.0369090\n",
            "\tspeed: 0.2065s/iter; left time: 121463.3236s\n",
            "\titers: 2800, epoch: 2 | loss: 0.0551612\n",
            "\tspeed: 0.1900s/iter; left time: 111770.1309s\n",
            "\titers: 2900, epoch: 2 | loss: 0.0751797\n",
            "\tspeed: 0.1907s/iter; left time: 112172.7334s\n",
            "\titers: 3000, epoch: 2 | loss: 0.0437290\n",
            "\tspeed: 0.1939s/iter; left time: 113998.1272s\n",
            "\titers: 3100, epoch: 2 | loss: 0.0445990\n",
            "\tspeed: 0.1952s/iter; left time: 114741.4342s\n",
            "\titers: 3200, epoch: 2 | loss: 0.0689264\n",
            "\tspeed: 0.1950s/iter; left time: 114612.4498s\n",
            "\titers: 3300, epoch: 2 | loss: 0.0340197\n",
            "\tspeed: 0.1921s/iter; left time: 112900.4882s\n",
            "\titers: 3400, epoch: 2 | loss: 0.0696424\n",
            "\tspeed: 0.1910s/iter; left time: 112266.8284s\n",
            "\titers: 3500, epoch: 2 | loss: 0.0268313\n",
            "\tspeed: 0.1897s/iter; left time: 111472.7878s\n",
            "\titers: 3600, epoch: 2 | loss: 0.0651480\n",
            "\tspeed: 0.1891s/iter; left time: 111107.1701s\n",
            "\titers: 3700, epoch: 2 | loss: 0.0413351\n",
            "\tspeed: 0.1917s/iter; left time: 112588.6198s\n",
            "\titers: 3800, epoch: 2 | loss: 0.0555700\n",
            "\tspeed: 0.1927s/iter; left time: 113181.9421s\n",
            "\titers: 3900, epoch: 2 | loss: 0.0503666\n",
            "\tspeed: 0.1899s/iter; left time: 111495.5148s\n",
            "\titers: 4000, epoch: 2 | loss: 0.0309685\n",
            "\tspeed: 0.1895s/iter; left time: 111247.9535s\n",
            "\titers: 4100, epoch: 2 | loss: 0.0552963\n",
            "\tspeed: 0.1908s/iter; left time: 111965.4063s\n",
            "\titers: 4200, epoch: 2 | loss: 0.0355678\n",
            "\tspeed: 0.2059s/iter; left time: 120824.3260s\n",
            "\titers: 4300, epoch: 2 | loss: 0.0213336\n",
            "\tspeed: 0.1883s/iter; left time: 110460.4092s\n",
            "\titers: 4400, epoch: 2 | loss: 0.0351462\n",
            "\tspeed: 0.1890s/iter; left time: 110852.4590s\n",
            "\titers: 4500, epoch: 2 | loss: 0.0356931\n",
            "\tspeed: 0.1919s/iter; left time: 112529.0569s\n",
            "\titers: 4600, epoch: 2 | loss: 0.0439625\n",
            "\tspeed: 0.1893s/iter; left time: 111027.4172s\n",
            "\titers: 4700, epoch: 2 | loss: 0.1224866\n",
            "\tspeed: 0.1912s/iter; left time: 112113.0162s\n",
            "\titers: 4800, epoch: 2 | loss: 0.0546439\n",
            "\tspeed: 0.2042s/iter; left time: 119718.9427s\n",
            "\titers: 4900, epoch: 2 | loss: 0.2019855\n",
            "\tspeed: 0.1903s/iter; left time: 111537.2313s\n",
            "\titers: 5000, epoch: 2 | loss: 0.0386020\n",
            "\tspeed: 0.1901s/iter; left time: 111402.5453s\n",
            "\titers: 5100, epoch: 2 | loss: 0.0216283\n",
            "\tspeed: 0.1921s/iter; left time: 112571.2480s\n",
            "\titers: 5200, epoch: 2 | loss: 0.0397268\n",
            "\tspeed: 0.1895s/iter; left time: 111020.6832s\n",
            "\titers: 5300, epoch: 2 | loss: 0.0385426\n",
            "\tspeed: 0.1932s/iter; left time: 113171.3131s\n",
            "\titers: 5400, epoch: 2 | loss: 0.0800017\n",
            "\tspeed: 0.1916s/iter; left time: 112216.9587s\n",
            "\titers: 5500, epoch: 2 | loss: 0.0811107\n",
            "\tspeed: 0.1912s/iter; left time: 111969.4020s\n",
            "\titers: 5600, epoch: 2 | loss: 0.0975744\n",
            "\tspeed: 0.1898s/iter; left time: 111119.7268s\n",
            "\titers: 5700, epoch: 2 | loss: 0.1487437\n",
            "\tspeed: 0.1906s/iter; left time: 111580.4719s\n",
            "\titers: 5800, epoch: 2 | loss: 0.1320282\n",
            "\tspeed: 0.1899s/iter; left time: 111162.8878s\n",
            "\titers: 5900, epoch: 2 | loss: 0.0368044\n",
            "\tspeed: 0.1897s/iter; left time: 110975.6320s\n",
            "Epoch: 2 cost time: 1153.0864510536194\n",
            "--------start to validate-----------\n",
            "normed mse:0.0464, mae:0.0816, rmse:0.2155, mape:3.8299, mspe:16793.8624, corr:0.7809\n",
            "denormed mse:36.6815, mae:2.2920, rmse:6.0565, mape:inf, mspe:inf, corr:0.7809\n",
            "--------start to test-----------\n",
            "normed mse:1.2182, mae:0.1876, rmse:1.1037, mape:0.3948, mspe:6.6390, corr:0.6025\n",
            "denormed mse:962.0589, mae:5.2720, rmse:31.0171, mape:inf, mspe:inf, corr:0.6025\n",
            "Epoch: 2, Steps: 5970 | Train Loss: 0.1072586 valid Loss: 0.0815592 Test Loss: 0.1875993\n",
            "Validation loss decreased (0.092384 --> 0.081559).  Saving model ...\n",
            "Updating learning rate to 9.025e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.0282377\n",
            "\tspeed: 1.4399s/iter; left time: 842267.8661s\n",
            "\titers: 200, epoch: 3 | loss: 0.0330692\n",
            "\tspeed: 0.1906s/iter; left time: 111451.8930s\n",
            "\titers: 300, epoch: 3 | loss: 0.0655546\n",
            "\tspeed: 0.1890s/iter; left time: 110504.3137s\n",
            "\titers: 400, epoch: 3 | loss: 0.0321864\n",
            "\tspeed: 0.1907s/iter; left time: 111495.2022s\n",
            "\titers: 500, epoch: 3 | loss: 0.0654953\n",
            "\tspeed: 0.1897s/iter; left time: 110893.1717s\n",
            "\titers: 600, epoch: 3 | loss: 0.0515916\n",
            "\tspeed: 0.1902s/iter; left time: 111147.8497s\n",
            "\titers: 700, epoch: 3 | loss: 0.0207999\n",
            "\tspeed: 0.1905s/iter; left time: 111293.1328s\n",
            "\titers: 800, epoch: 3 | loss: 0.0458248\n",
            "\tspeed: 0.1892s/iter; left time: 110551.8197s\n",
            "\titers: 900, epoch: 3 | loss: 0.0421723\n",
            "\tspeed: 0.1898s/iter; left time: 110850.0756s\n",
            "\titers: 1000, epoch: 3 | loss: 0.0353909\n",
            "\tspeed: 0.1921s/iter; left time: 112218.4253s\n",
            "\titers: 1100, epoch: 3 | loss: 0.0692010\n",
            "\tspeed: 0.1912s/iter; left time: 111652.6868s\n",
            "\titers: 1200, epoch: 3 | loss: 0.0769647\n",
            "\tspeed: 0.2019s/iter; left time: 117868.7059s\n",
            "\titers: 1300, epoch: 3 | loss: 0.0518479\n",
            "\tspeed: 0.1902s/iter; left time: 111044.3289s\n",
            "\titers: 1400, epoch: 3 | loss: 0.0524641\n",
            "\tspeed: 0.1897s/iter; left time: 110734.5299s\n",
            "\titers: 1500, epoch: 3 | loss: 0.0785010\n",
            "\tspeed: 0.1915s/iter; left time: 111732.1906s\n",
            "\titers: 1600, epoch: 3 | loss: 0.0204456\n",
            "\tspeed: 0.1891s/iter; left time: 110338.0121s\n",
            "\titers: 1700, epoch: 3 | loss: 0.0436295\n",
            "\tspeed: 0.1895s/iter; left time: 110558.8182s\n",
            "\titers: 1800, epoch: 3 | loss: 0.0377591\n",
            "\tspeed: 0.1886s/iter; left time: 110028.8767s\n",
            "\titers: 1900, epoch: 3 | loss: 0.0337633\n",
            "\tspeed: 0.1897s/iter; left time: 110616.1554s\n",
            "\titers: 2000, epoch: 3 | loss: 0.0223792\n",
            "\tspeed: 0.1902s/iter; left time: 110921.5604s\n",
            "\titers: 2100, epoch: 3 | loss: 0.0258499\n",
            "\tspeed: 0.1902s/iter; left time: 110869.5265s\n",
            "\titers: 2200, epoch: 3 | loss: 0.0430848\n",
            "\tspeed: 0.1884s/iter; left time: 109834.1787s\n",
            "\titers: 2300, epoch: 3 | loss: 0.0442455\n",
            "\tspeed: 0.1900s/iter; left time: 110750.3663s\n",
            "\titers: 2400, epoch: 3 | loss: 0.0360532\n",
            "\tspeed: 0.1889s/iter; left time: 110085.2066s\n",
            "\titers: 2500, epoch: 3 | loss: 0.0438006\n",
            "\tspeed: 0.1894s/iter; left time: 110315.1919s\n",
            "\titers: 2600, epoch: 3 | loss: 0.0245544\n",
            "\tspeed: 0.1886s/iter; left time: 109870.4720s\n",
            "\titers: 2700, epoch: 3 | loss: 0.0356791\n",
            "\tspeed: 0.2065s/iter; left time: 120261.9221s\n",
            "\titers: 2800, epoch: 3 | loss: 0.0333067\n",
            "\tspeed: 0.1895s/iter; left time: 110344.3569s\n",
            "\titers: 2900, epoch: 3 | loss: 0.0320523\n",
            "\tspeed: 0.1923s/iter; left time: 111964.4826s\n",
            "\titers: 3000, epoch: 3 | loss: 0.0648587\n",
            "\tspeed: 0.1909s/iter; left time: 111125.8469s\n",
            "\titers: 3100, epoch: 3 | loss: 0.0226716\n",
            "\tspeed: 0.1913s/iter; left time: 111331.1810s\n",
            "\titers: 3200, epoch: 3 | loss: 0.0248657\n",
            "\tspeed: 0.1906s/iter; left time: 110886.1257s\n",
            "\titers: 3300, epoch: 3 | loss: 0.0366311\n",
            "\tspeed: 0.1888s/iter; left time: 109858.6227s\n",
            "\titers: 3400, epoch: 3 | loss: 0.0430514\n",
            "\tspeed: 0.1872s/iter; left time: 108887.2306s\n",
            "\titers: 3500, epoch: 3 | loss: 0.0237854\n",
            "\tspeed: 0.1878s/iter; left time: 109224.5903s\n",
            "\titers: 3600, epoch: 3 | loss: 0.0727962\n",
            "\tspeed: 0.1917s/iter; left time: 111439.2407s\n",
            "\titers: 3700, epoch: 3 | loss: 0.0231481\n",
            "\tspeed: 0.1940s/iter; left time: 112802.8380s\n",
            "\titers: 3800, epoch: 3 | loss: 0.0177866\n",
            "\tspeed: 0.1940s/iter; left time: 112736.1584s\n",
            "\titers: 3900, epoch: 3 | loss: 0.0299327\n",
            "\tspeed: 0.1930s/iter; left time: 112184.4590s\n",
            "\titers: 4000, epoch: 3 | loss: 0.0967206\n",
            "\tspeed: 0.1906s/iter; left time: 110746.0605s\n",
            "\titers: 4100, epoch: 3 | loss: 0.0326234\n",
            "\tspeed: 0.1889s/iter; left time: 109716.6137s\n",
            "\titers: 4200, epoch: 3 | loss: 0.0215993\n",
            "\tspeed: 0.2077s/iter; left time: 120659.7074s\n",
            "\titers: 4300, epoch: 3 | loss: 0.0284998\n",
            "\tspeed: 0.1899s/iter; left time: 110275.2817s\n",
            "\titers: 4400, epoch: 3 | loss: 0.0209158\n",
            "\tspeed: 0.1925s/iter; left time: 111752.6970s\n",
            "\titers: 4500, epoch: 3 | loss: 0.0373075\n",
            "\tspeed: 0.1902s/iter; left time: 110421.6017s\n",
            "\titers: 4600, epoch: 3 | loss: 0.0228305\n",
            "\tspeed: 0.1908s/iter; left time: 110738.1717s\n",
            "\titers: 4700, epoch: 3 | loss: 0.0291155\n",
            "\tspeed: 0.1883s/iter; left time: 109258.6898s\n",
            "\titers: 4800, epoch: 3 | loss: 0.0565343\n",
            "\tspeed: 0.1895s/iter; left time: 109940.8759s\n",
            "\titers: 4900, epoch: 3 | loss: 0.0555845\n",
            "\tspeed: 0.1878s/iter; left time: 108982.7962s\n",
            "\titers: 5000, epoch: 3 | loss: 0.0383891\n",
            "\tspeed: 0.1882s/iter; left time: 109187.1886s\n",
            "\titers: 5100, epoch: 3 | loss: 0.0794580\n",
            "\tspeed: 0.1916s/iter; left time: 111134.3140s\n",
            "\titers: 5200, epoch: 3 | loss: 0.0212199\n",
            "\tspeed: 0.1896s/iter; left time: 109965.6473s\n",
            "\titers: 5300, epoch: 3 | loss: 0.0350561\n",
            "\tspeed: 0.1926s/iter; left time: 111682.8448s\n",
            "\titers: 5400, epoch: 3 | loss: 0.1133359\n",
            "\tspeed: 0.1891s/iter; left time: 109629.3024s\n",
            "\titers: 5500, epoch: 3 | loss: 0.0234400\n",
            "\tspeed: 0.1881s/iter; left time: 109025.2897s\n",
            "\titers: 5600, epoch: 3 | loss: 0.1148249\n",
            "\tspeed: 0.1909s/iter; left time: 110613.0836s\n",
            "\titers: 5700, epoch: 3 | loss: 0.0321795\n",
            "\tspeed: 0.2056s/iter; left time: 119121.1326s\n",
            "\titers: 5800, epoch: 3 | loss: 0.0229939\n",
            "\tspeed: 0.1905s/iter; left time: 110373.2867s\n",
            "\titers: 5900, epoch: 3 | loss: 0.0277371\n",
            "\tspeed: 0.1906s/iter; left time: 110390.7057s\n",
            "Epoch: 3 cost time: 1141.3254034519196\n",
            "--------start to validate-----------\n",
            "normed mse:0.0442, mae:0.0769, rmse:0.2102, mape:3.5092, mspe:11970.0429, corr:0.7929\n",
            "denormed mse:34.8928, mae:2.1615, rmse:5.9070, mape:inf, mspe:inf, corr:0.7929\n",
            "--------start to test-----------\n",
            "normed mse:1.1808, mae:0.1790, rmse:1.0867, mape:0.3691, mspe:6.1540, corr:0.6167\n",
            "denormed mse:932.5659, mae:5.0296, rmse:30.5379, mape:inf, mspe:inf, corr:0.6167\n",
            "Epoch: 3, Steps: 5970 | Train Loss: 0.0858227 valid Loss: 0.0769149 Test Loss: 0.1789744\n",
            "Validation loss decreased (0.081559 --> 0.076915).  Saving model ...\n",
            "Updating learning rate to 8.573749999999999e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.0335467\n",
            "\tspeed: 1.4481s/iter; left time: 838451.4551s\n",
            "\titers: 200, epoch: 4 | loss: 0.0348435\n",
            "\tspeed: 0.1934s/iter; left time: 111974.8706s\n",
            "\titers: 300, epoch: 4 | loss: 0.0489070\n",
            "\tspeed: 0.1927s/iter; left time: 111516.9575s\n",
            "\titers: 400, epoch: 4 | loss: 0.0382525\n",
            "\tspeed: 0.1951s/iter; left time: 112917.0499s\n",
            "\titers: 500, epoch: 4 | loss: 0.0327185\n",
            "\tspeed: 0.1925s/iter; left time: 111400.0679s\n",
            "\titers: 600, epoch: 4 | loss: 0.0807521\n",
            "\tspeed: 0.1923s/iter; left time: 111246.7806s\n",
            "\titers: 700, epoch: 4 | loss: 0.0353455\n",
            "\tspeed: 0.2097s/iter; left time: 121307.6933s\n",
            "\titers: 800, epoch: 4 | loss: 0.0494184\n",
            "\tspeed: 0.1944s/iter; left time: 112428.2914s\n",
            "\titers: 900, epoch: 4 | loss: 0.0850873\n",
            "\tspeed: 0.1933s/iter; left time: 111757.3749s\n",
            "\titers: 1000, epoch: 4 | loss: 0.1083001\n",
            "\tspeed: 0.1930s/iter; left time: 111566.6092s\n",
            "\titers: 1100, epoch: 4 | loss: 0.0612042\n",
            "\tspeed: 0.1957s/iter; left time: 113124.4221s\n",
            "\titers: 1200, epoch: 4 | loss: 0.0261910\n",
            "\tspeed: 0.1909s/iter; left time: 110343.7674s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0310305\n",
            "\tspeed: 0.1908s/iter; left time: 110263.6473s\n",
            "\titers: 1400, epoch: 4 | loss: 0.0239146\n",
            "\tspeed: 0.1888s/iter; left time: 109045.6083s\n",
            "\titers: 1500, epoch: 4 | loss: 0.0233259\n",
            "\tspeed: 0.1901s/iter; left time: 109792.1487s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0348631\n",
            "\tspeed: 0.1905s/iter; left time: 110039.3739s\n",
            "\titers: 1700, epoch: 4 | loss: 0.0377471\n",
            "\tspeed: 0.1887s/iter; left time: 108964.6209s\n",
            "\titers: 1800, epoch: 4 | loss: 0.0866146\n",
            "\tspeed: 0.1899s/iter; left time: 109610.5422s\n",
            "\titers: 1900, epoch: 4 | loss: 0.0187963\n",
            "\tspeed: 0.1958s/iter; left time: 113025.6917s\n",
            "\titers: 2000, epoch: 4 | loss: 0.0448701\n",
            "\tspeed: 0.1958s/iter; left time: 112993.2190s\n",
            "\titers: 2100, epoch: 4 | loss: 0.0392022\n",
            "\tspeed: 0.1993s/iter; left time: 114980.7716s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0205051\n",
            "\tspeed: 0.1962s/iter; left time: 113173.3583s\n",
            "\titers: 2300, epoch: 4 | loss: 0.0201700\n",
            "\tspeed: 0.1892s/iter; left time: 109152.7018s\n",
            "\titers: 2400, epoch: 4 | loss: 0.0213298\n",
            "\tspeed: 0.1909s/iter; left time: 110109.7324s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0421097\n",
            "\tspeed: 0.1917s/iter; left time: 110529.9877s\n",
            "\titers: 2600, epoch: 4 | loss: 0.0206433\n",
            "\tspeed: 0.1879s/iter; left time: 108313.2491s\n",
            "\titers: 2700, epoch: 4 | loss: 0.0710697\n",
            "\tspeed: 0.1884s/iter; left time: 108587.2720s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0283310\n",
            "\tspeed: 0.1888s/iter; left time: 108821.5140s\n",
            "\titers: 2900, epoch: 4 | loss: 0.0194378\n",
            "\tspeed: 0.1900s/iter; left time: 109484.1382s\n",
            "\titers: 3000, epoch: 4 | loss: 0.0366179\n",
            "\tspeed: 0.1891s/iter; left time: 108927.3686s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0492878\n",
            "\tspeed: 0.1907s/iter; left time: 109851.2157s\n",
            "\titers: 3200, epoch: 4 | loss: 0.0240414\n",
            "\tspeed: 0.1883s/iter; left time: 108464.3468s\n",
            "\titers: 3300, epoch: 4 | loss: 0.0601570\n",
            "\tspeed: 0.1913s/iter; left time: 110121.5869s\n",
            "\titers: 3400, epoch: 4 | loss: 0.0462635\n",
            "\tspeed: 0.1926s/iter; left time: 110869.6673s\n",
            "\titers: 3500, epoch: 4 | loss: 0.0169734\n",
            "\tspeed: 0.1936s/iter; left time: 111418.2154s\n",
            "\titers: 3600, epoch: 4 | loss: 0.0214919\n",
            "\tspeed: 0.2125s/iter; left time: 122293.3879s\n",
            "\titers: 3700, epoch: 4 | loss: 0.0406382\n",
            "\tspeed: 0.1939s/iter; left time: 111561.1298s\n",
            "\titers: 3800, epoch: 4 | loss: 0.0228733\n",
            "\tspeed: 0.1894s/iter; left time: 108980.6856s\n",
            "\titers: 3900, epoch: 4 | loss: 0.0295925\n",
            "\tspeed: 0.1890s/iter; left time: 108738.2731s\n",
            "\titers: 4000, epoch: 4 | loss: 0.0460381\n",
            "\tspeed: 0.1896s/iter; left time: 109039.6670s\n",
            "\titers: 4100, epoch: 4 | loss: 0.0197935\n",
            "\tspeed: 0.1893s/iter; left time: 108838.0197s\n",
            "\titers: 4200, epoch: 4 | loss: 0.0206656\n",
            "\tspeed: 0.1894s/iter; left time: 108862.0868s\n",
            "\titers: 4300, epoch: 4 | loss: 0.0220319\n",
            "\tspeed: 0.1889s/iter; left time: 108563.5874s\n",
            "\titers: 4400, epoch: 4 | loss: 0.0177252\n",
            "\tspeed: 0.1881s/iter; left time: 108091.4079s\n",
            "\titers: 4500, epoch: 4 | loss: 0.0269572\n",
            "\tspeed: 0.1881s/iter; left time: 108059.8109s\n",
            "\titers: 4600, epoch: 4 | loss: 0.0339995\n",
            "\tspeed: 0.1906s/iter; left time: 109523.3674s\n",
            "\titers: 4700, epoch: 4 | loss: 0.0350758\n",
            "\tspeed: 0.1881s/iter; left time: 108014.3306s\n",
            "\titers: 4800, epoch: 4 | loss: 0.0133388\n",
            "\tspeed: 0.1891s/iter; left time: 108592.3000s\n",
            "\titers: 4900, epoch: 4 | loss: 0.0982719\n",
            "\tspeed: 0.1897s/iter; left time: 108950.7936s\n",
            "\titers: 5000, epoch: 4 | loss: 0.1103684\n",
            "\tspeed: 0.1897s/iter; left time: 108919.3498s\n",
            "\titers: 5100, epoch: 4 | loss: 0.1249440\n",
            "\tspeed: 0.2046s/iter; left time: 117418.0012s\n",
            "\titers: 5200, epoch: 4 | loss: 0.0285790\n",
            "\tspeed: 0.1912s/iter; left time: 109705.7106s\n",
            "\titers: 5300, epoch: 4 | loss: 0.0297409\n",
            "\tspeed: 0.1883s/iter; left time: 108072.4092s\n",
            "\titers: 5400, epoch: 4 | loss: 0.0175151\n",
            "\tspeed: 0.1904s/iter; left time: 109205.1530s\n",
            "\titers: 5500, epoch: 4 | loss: 0.0796432\n",
            "\tspeed: 0.1887s/iter; left time: 108210.6185s\n",
            "\titers: 5600, epoch: 4 | loss: 0.0294607\n",
            "\tspeed: 0.1888s/iter; left time: 108280.5078s\n",
            "\titers: 5700, epoch: 4 | loss: 0.0293857\n",
            "\tspeed: 0.1886s/iter; left time: 108159.6256s\n",
            "\titers: 5800, epoch: 4 | loss: 0.0227476\n",
            "\tspeed: 0.1896s/iter; left time: 108696.0968s\n",
            "\titers: 5900, epoch: 4 | loss: 0.0215280\n",
            "\tspeed: 0.1885s/iter; left time: 108035.0523s\n",
            "Epoch: 4 cost time: 1145.220628976822\n",
            "--------start to validate-----------\n",
            "normed mse:0.0422, mae:0.0707, rmse:0.2055, mape:2.8152, mspe:6473.4400, corr:0.8019\n",
            "denormed mse:33.3643, mae:1.9862, rmse:5.7762, mape:inf, mspe:inf, corr:0.8019\n",
            "--------start to test-----------\n",
            "normed mse:1.1535, mae:0.1695, rmse:1.0740, mape:0.3383, mspe:5.6936, corr:0.6254\n",
            "denormed mse:910.9387, mae:4.7640, rmse:30.1818, mape:inf, mspe:inf, corr:0.6254\n",
            "Epoch: 4, Steps: 5970 | Train Loss: 0.0784547 valid Loss: 0.0706769 Test Loss: 0.1695214\n",
            "Validation loss decreased (0.076915 --> 0.070677).  Saving model ...\n",
            "Updating learning rate to 8.1450625e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0345659\n",
            "\tspeed: 1.4276s/iter; left time: 818030.3184s\n",
            "\titers: 200, epoch: 5 | loss: 0.0142095\n",
            "\tspeed: 0.1894s/iter; left time: 108521.5629s\n",
            "\titers: 300, epoch: 5 | loss: 0.0599549\n",
            "\tspeed: 0.1919s/iter; left time: 109927.7918s\n",
            "\titers: 400, epoch: 5 | loss: 0.0640673\n",
            "\tspeed: 0.1895s/iter; left time: 108507.5956s\n",
            "\titers: 500, epoch: 5 | loss: 0.0317453\n",
            "\tspeed: 0.1908s/iter; left time: 109237.4072s\n",
            "\titers: 600, epoch: 5 | loss: 0.0224505\n",
            "\tspeed: 0.1912s/iter; left time: 109448.2832s\n",
            "\titers: 700, epoch: 5 | loss: 0.0434827\n",
            "\tspeed: 0.1878s/iter; left time: 107509.8621s\n",
            "\titers: 800, epoch: 5 | loss: 0.0212530\n",
            "\tspeed: 0.1896s/iter; left time: 108532.9199s\n",
            "\titers: 900, epoch: 5 | loss: 0.0251126\n",
            "\tspeed: 0.1879s/iter; left time: 107545.5376s\n",
            "\titers: 1000, epoch: 5 | loss: 0.1114487\n",
            "\tspeed: 0.1898s/iter; left time: 108591.0416s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0238211\n",
            "\tspeed: 0.1877s/iter; left time: 107389.7288s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0223723\n",
            "\tspeed: 0.1891s/iter; left time: 108169.5097s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0417902\n",
            "\tspeed: 0.1904s/iter; left time: 108872.8531s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0306941\n",
            "\tspeed: 0.1907s/iter; left time: 109012.1894s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0835161\n",
            "\tspeed: 0.1887s/iter; left time: 107861.1901s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0286183\n",
            "\tspeed: 0.2031s/iter; left time: 116075.1313s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0477282\n",
            "\tspeed: 0.1906s/iter; left time: 108909.2143s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0210926\n",
            "\tspeed: 0.1913s/iter; left time: 109300.4069s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0275005\n",
            "\tspeed: 0.1930s/iter; left time: 110271.8366s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0123415\n",
            "\tspeed: 0.1898s/iter; left time: 108411.6867s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0323503\n",
            "\tspeed: 0.1915s/iter; left time: 109340.8573s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0475750\n",
            "\tspeed: 0.1904s/iter; left time: 108679.0203s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0320321\n",
            "\tspeed: 0.1914s/iter; left time: 109274.4423s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0321801\n",
            "\tspeed: 0.1901s/iter; left time: 108498.9824s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0533498\n",
            "\tspeed: 0.1895s/iter; left time: 108111.1327s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0239723\n",
            "\tspeed: 0.1908s/iter; left time: 108863.3460s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0243877\n",
            "\tspeed: 0.1902s/iter; left time: 108483.6076s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0822888\n",
            "\tspeed: 0.1909s/iter; left time: 108883.6865s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0387312\n",
            "\tspeed: 0.1897s/iter; left time: 108162.8171s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0445649\n",
            "\tspeed: 0.1893s/iter; left time: 107937.0104s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0184178\n",
            "\tspeed: 0.2043s/iter; left time: 116429.1850s\n",
            "\titers: 3200, epoch: 5 | loss: 0.0258497\n",
            "\tspeed: 0.1897s/iter; left time: 108096.7476s\n",
            "\titers: 3300, epoch: 5 | loss: 0.0250476\n",
            "\tspeed: 0.1899s/iter; left time: 108205.7732s\n",
            "\titers: 3400, epoch: 5 | loss: 0.0283967\n",
            "\tspeed: 0.1876s/iter; left time: 106863.9451s\n",
            "\titers: 3500, epoch: 5 | loss: 0.0426186\n",
            "\tspeed: 0.1908s/iter; left time: 108666.9942s\n",
            "\titers: 3600, epoch: 5 | loss: 0.0159160\n",
            "\tspeed: 0.1908s/iter; left time: 108684.1675s\n",
            "\titers: 3700, epoch: 5 | loss: 0.0311891\n",
            "\tspeed: 0.1905s/iter; left time: 108500.8613s\n",
            "\titers: 3800, epoch: 5 | loss: 0.0982281\n",
            "\tspeed: 0.1905s/iter; left time: 108452.4767s\n",
            "\titers: 3900, epoch: 5 | loss: 0.0646807\n",
            "\tspeed: 0.1903s/iter; left time: 108302.2771s\n",
            "\titers: 4000, epoch: 5 | loss: 0.0361919\n",
            "\tspeed: 0.1912s/iter; left time: 108827.0041s\n",
            "\titers: 4100, epoch: 5 | loss: 0.0261517\n",
            "\tspeed: 0.1908s/iter; left time: 108572.6129s\n",
            "\titers: 4200, epoch: 5 | loss: 0.0418934\n",
            "\tspeed: 0.1891s/iter; left time: 107591.8868s\n",
            "\titers: 4300, epoch: 5 | loss: 0.0341657\n",
            "\tspeed: 0.1903s/iter; left time: 108261.0346s\n",
            "\titers: 4400, epoch: 5 | loss: 0.0375772\n",
            "\tspeed: 0.1908s/iter; left time: 108518.3813s\n",
            "\titers: 4500, epoch: 5 | loss: 0.0478201\n",
            "\tspeed: 0.1896s/iter; left time: 107796.5713s\n",
            "\titers: 4600, epoch: 5 | loss: 0.0362712\n",
            "\tspeed: 0.1882s/iter; left time: 107001.4667s\n",
            "\titers: 4700, epoch: 5 | loss: 0.0579484\n",
            "\tspeed: 0.2023s/iter; left time: 114997.6913s\n",
            "\titers: 4800, epoch: 5 | loss: 0.0460380\n",
            "\tspeed: 0.1912s/iter; left time: 108656.0668s\n",
            "\titers: 4900, epoch: 5 | loss: 0.0184941\n",
            "\tspeed: 0.1897s/iter; left time: 107792.3367s\n",
            "\titers: 5000, epoch: 5 | loss: 0.3256850\n",
            "\tspeed: 0.1890s/iter; left time: 107369.3174s\n",
            "\titers: 5100, epoch: 5 | loss: 0.0180487\n",
            "\tspeed: 0.1893s/iter; left time: 107542.1245s\n",
            "\titers: 5200, epoch: 5 | loss: 0.0398474\n",
            "\tspeed: 0.1905s/iter; left time: 108187.8047s\n",
            "\titers: 5300, epoch: 5 | loss: 0.0840403\n",
            "\tspeed: 0.1896s/iter; left time: 107660.7246s\n",
            "\titers: 5400, epoch: 5 | loss: 0.0389567\n",
            "\tspeed: 0.1885s/iter; left time: 106990.7259s\n",
            "\titers: 5500, epoch: 5 | loss: 0.1061061\n",
            "\tspeed: 0.1898s/iter; left time: 107714.0701s\n",
            "\titers: 5600, epoch: 5 | loss: 0.0467439\n",
            "\tspeed: 0.1896s/iter; left time: 107578.9687s\n",
            "\titers: 5700, epoch: 5 | loss: 0.0270384\n",
            "\tspeed: 0.1893s/iter; left time: 107407.3370s\n",
            "\titers: 5800, epoch: 5 | loss: 0.0867703\n",
            "\tspeed: 0.1882s/iter; left time: 106791.3033s\n",
            "\titers: 5900, epoch: 5 | loss: 0.1710134\n",
            "\tspeed: 0.1894s/iter; left time: 107405.7222s\n",
            "Epoch: 5 cost time: 1139.3788967132568\n",
            "--------start to validate-----------\n",
            "normed mse:0.0418, mae:0.0712, rmse:0.2044, mape:2.7298, mspe:6586.4617, corr:0.8038\n",
            "denormed mse:33.0022, mae:2.0000, rmse:5.7448, mape:inf, mspe:inf, corr:0.8038\n",
            "--------start to test-----------\n",
            "normed mse:1.1402, mae:0.1716, rmse:1.0678, mape:0.3344, mspe:5.2110, corr:0.6296\n",
            "denormed mse:900.5053, mae:4.8225, rmse:30.0084, mape:inf, mspe:inf, corr:0.6296\n",
            "Epoch: 5, Steps: 5970 | Train Loss: 0.0746460 valid Loss: 0.0711695 Test Loss: 0.1716035\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 7.737809374999998e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.0238092\n",
            "\tspeed: 1.4263s/iter; left time: 808796.2051s\n",
            "\titers: 200, epoch: 6 | loss: 0.0345656\n",
            "\tspeed: 0.1881s/iter; left time: 106638.9626s\n",
            "\titers: 300, epoch: 6 | loss: 0.0218761\n",
            "\tspeed: 0.1908s/iter; left time: 108152.9269s\n",
            "\titers: 400, epoch: 6 | loss: 0.0471466\n",
            "\tspeed: 0.1960s/iter; left time: 111099.4374s\n",
            "\titers: 500, epoch: 6 | loss: 0.0209262\n",
            "\tspeed: 0.1967s/iter; left time: 111457.5096s\n",
            "\titers: 600, epoch: 6 | loss: 0.1352208\n",
            "\tspeed: 0.1904s/iter; left time: 107872.3422s\n",
            "\titers: 700, epoch: 6 | loss: 0.0371093\n",
            "\tspeed: 0.1901s/iter; left time: 107701.0722s\n",
            "\titers: 800, epoch: 6 | loss: 0.0304970\n",
            "\tspeed: 0.1931s/iter; left time: 109386.3886s\n",
            "\titers: 900, epoch: 6 | loss: 0.1507580\n",
            "\tspeed: 0.1913s/iter; left time: 108345.0788s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0278762\n",
            "\tspeed: 0.1921s/iter; left time: 108753.9993s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0951791\n",
            "\tspeed: 0.1926s/iter; left time: 108999.2882s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0245088\n",
            "\tspeed: 0.2040s/iter; left time: 115438.1728s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0806321\n",
            "\tspeed: 0.1888s/iter; left time: 106853.9784s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0134997\n",
            "\tspeed: 0.1894s/iter; left time: 107132.7857s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0582555\n",
            "\tspeed: 0.1901s/iter; left time: 107537.5565s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0598680\n",
            "\tspeed: 0.1887s/iter; left time: 106722.4300s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0343101\n",
            "\tspeed: 0.1887s/iter; left time: 106708.6784s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0228399\n",
            "\tspeed: 0.1892s/iter; left time: 106977.3684s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0250899\n",
            "\tspeed: 0.1900s/iter; left time: 107409.7745s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0268102\n",
            "\tspeed: 0.1901s/iter; left time: 107422.8303s\n",
            "\titers: 2100, epoch: 6 | loss: 0.1028499\n",
            "\tspeed: 0.1909s/iter; left time: 107850.7193s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0334070\n",
            "\tspeed: 0.1893s/iter; left time: 106968.1780s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0422024\n",
            "\tspeed: 0.1877s/iter; left time: 106018.1706s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0251520\n",
            "\tspeed: 0.1875s/iter; left time: 105912.9822s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0198269\n",
            "\tspeed: 0.1881s/iter; left time: 106208.8213s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0302806\n",
            "\tspeed: 0.1884s/iter; left time: 106336.6174s\n",
            "\titers: 2700, epoch: 6 | loss: 0.9439988\n",
            "\tspeed: 0.1878s/iter; left time: 106011.1351s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0583379\n",
            "\tspeed: 0.2021s/iter; left time: 114038.6206s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0328670\n",
            "\tspeed: 0.1889s/iter; left time: 106611.2753s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0224309\n",
            "\tspeed: 0.1889s/iter; left time: 106584.5407s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0143792\n",
            "\tspeed: 0.1884s/iter; left time: 106274.1713s\n",
            "\titers: 3200, epoch: 6 | loss: 0.0179282\n",
            "\tspeed: 0.1889s/iter; left time: 106523.4791s\n",
            "\titers: 3300, epoch: 6 | loss: 0.0599164\n",
            "\tspeed: 0.1882s/iter; left time: 106107.9444s\n",
            "\titers: 3400, epoch: 6 | loss: 0.0287851\n",
            "\tspeed: 0.1860s/iter; left time: 104854.5363s\n",
            "\titers: 3500, epoch: 6 | loss: 0.0285165\n",
            "\tspeed: 0.1895s/iter; left time: 106786.4607s\n",
            "\titers: 3600, epoch: 6 | loss: 0.0284778\n",
            "\tspeed: 0.1853s/iter; left time: 104414.2126s\n",
            "\titers: 3700, epoch: 6 | loss: 0.0647889\n",
            "\tspeed: 0.1849s/iter; left time: 104180.0373s\n",
            "\titers: 3800, epoch: 6 | loss: 0.0679852\n",
            "\tspeed: 0.1877s/iter; left time: 105732.5531s\n",
            "\titers: 3900, epoch: 6 | loss: 0.0275471\n",
            "\tspeed: 0.1852s/iter; left time: 104319.5426s\n",
            "\titers: 4000, epoch: 6 | loss: 0.0195936\n",
            "\tspeed: 0.1871s/iter; left time: 105382.9881s\n",
            "\titers: 4100, epoch: 6 | loss: 0.3032618\n",
            "\tspeed: 0.1861s/iter; left time: 104777.1831s\n",
            "\titers: 4200, epoch: 6 | loss: 0.0191045\n",
            "\tspeed: 0.1874s/iter; left time: 105482.8105s\n",
            "\titers: 4300, epoch: 6 | loss: 0.0950629\n",
            "\tspeed: 0.1999s/iter; left time: 112491.7112s\n",
            "\titers: 4400, epoch: 6 | loss: 0.0875934\n",
            "\tspeed: 0.1859s/iter; left time: 104616.5052s\n",
            "\titers: 4500, epoch: 6 | loss: 0.0344209\n",
            "\tspeed: 0.1866s/iter; left time: 104967.3356s\n",
            "\titers: 4600, epoch: 6 | loss: 0.0397074\n",
            "\tspeed: 0.1892s/iter; left time: 106435.0896s\n",
            "\titers: 4700, epoch: 6 | loss: 0.0167386\n",
            "\tspeed: 0.1906s/iter; left time: 107211.6930s\n",
            "\titers: 4800, epoch: 6 | loss: 0.0235476\n",
            "\tspeed: 0.1931s/iter; left time: 108584.1428s\n",
            "\titers: 4900, epoch: 6 | loss: 0.0588173\n",
            "\tspeed: 0.1994s/iter; left time: 112088.3961s\n",
            "\titers: 5000, epoch: 6 | loss: 0.0823924\n",
            "\tspeed: 0.2014s/iter; left time: 113216.4387s\n",
            "\titers: 5100, epoch: 6 | loss: 0.0186853\n",
            "\tspeed: 0.1974s/iter; left time: 110921.4932s\n",
            "\titers: 5200, epoch: 6 | loss: 0.0402807\n",
            "\tspeed: 0.1920s/iter; left time: 107906.0100s\n",
            "\titers: 5300, epoch: 6 | loss: 0.1196644\n",
            "\tspeed: 0.1905s/iter; left time: 107036.6312s\n",
            "\titers: 5400, epoch: 6 | loss: 0.0251179\n",
            "\tspeed: 0.1903s/iter; left time: 106917.9781s\n",
            "\titers: 5500, epoch: 6 | loss: 0.0508721\n",
            "\tspeed: 0.1951s/iter; left time: 109574.4878s\n",
            "\titers: 5600, epoch: 6 | loss: 0.0181579\n",
            "\tspeed: 0.1933s/iter; left time: 108568.3109s\n",
            "\titers: 5700, epoch: 6 | loss: 0.1790614\n",
            "\tspeed: 0.1918s/iter; left time: 107682.9061s\n",
            "\titers: 5800, epoch: 6 | loss: 0.0908012\n",
            "\tspeed: 0.2051s/iter; left time: 115157.0695s\n",
            "\titers: 5900, epoch: 6 | loss: 0.0824459\n",
            "\tspeed: 0.1901s/iter; left time: 106678.4279s\n",
            "Epoch: 6 cost time: 1139.8294978141785\n",
            "--------start to validate-----------\n",
            "normed mse:0.0415, mae:0.0706, rmse:0.2037, mape:2.6705, mspe:5595.8470, corr:0.8046\n",
            "denormed mse:32.7850, mae:1.9834, rmse:5.7258, mape:inf, mspe:inf, corr:0.8046\n",
            "--------start to test-----------\n",
            "normed mse:1.1440, mae:0.1775, rmse:1.0696, mape:0.3360, mspe:5.1011, corr:0.6275\n",
            "denormed mse:903.4627, mae:4.9894, rmse:30.0577, mape:inf, mspe:inf, corr:0.6275\n",
            "Epoch: 6, Steps: 5970 | Train Loss: 0.0720021 valid Loss: 0.0705784 Test Loss: 0.1775421\n",
            "Validation loss decreased (0.070677 --> 0.070578).  Saving model ...\n",
            "Updating learning rate to 7.350918906249998e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.0333342\n",
            "\tspeed: 1.4226s/iter; left time: 798184.5909s\n",
            "\titers: 200, epoch: 7 | loss: 0.0701634\n",
            "\tspeed: 0.1916s/iter; left time: 107492.9453s\n",
            "\titers: 300, epoch: 7 | loss: 0.0254134\n",
            "\tspeed: 0.1895s/iter; left time: 106274.2018s\n",
            "\titers: 400, epoch: 7 | loss: 0.0242106\n",
            "\tspeed: 0.1914s/iter; left time: 107345.9168s\n",
            "\titers: 500, epoch: 7 | loss: 0.0274353\n",
            "\tspeed: 0.1881s/iter; left time: 105467.8080s\n",
            "\titers: 600, epoch: 7 | loss: 0.0268588\n",
            "\tspeed: 0.1918s/iter; left time: 107514.8399s\n",
            "\titers: 700, epoch: 7 | loss: 0.0266356\n",
            "\tspeed: 0.2058s/iter; left time: 115355.7688s\n",
            "\titers: 800, epoch: 7 | loss: 0.0234277\n",
            "\tspeed: 0.1886s/iter; left time: 105683.2587s\n",
            "\titers: 900, epoch: 7 | loss: 0.0172643\n",
            "\tspeed: 0.1904s/iter; left time: 106664.7465s\n",
            "\titers: 1000, epoch: 7 | loss: 0.0251706\n",
            "\tspeed: 0.1896s/iter; left time: 106219.9714s\n",
            "\titers: 1100, epoch: 7 | loss: 0.0240178\n",
            "\tspeed: 0.1888s/iter; left time: 105724.9646s\n",
            "\titers: 1200, epoch: 7 | loss: 0.0332139\n",
            "\tspeed: 0.1881s/iter; left time: 105358.1638s\n",
            "\titers: 1300, epoch: 7 | loss: 0.0577170\n",
            "\tspeed: 0.1879s/iter; left time: 105206.3638s\n",
            "\titers: 1400, epoch: 7 | loss: 0.0366278\n",
            "\tspeed: 0.1894s/iter; left time: 106013.0766s\n",
            "\titers: 1500, epoch: 7 | loss: 0.0299100\n",
            "\tspeed: 0.1894s/iter; left time: 105998.1775s\n",
            "\titers: 1600, epoch: 7 | loss: 0.0812987\n",
            "\tspeed: 0.1888s/iter; left time: 105648.7213s\n",
            "\titers: 1700, epoch: 7 | loss: 0.0373695\n",
            "\tspeed: 0.1897s/iter; left time: 106156.5678s\n",
            "\titers: 1800, epoch: 7 | loss: 0.0183773\n",
            "\tspeed: 0.1912s/iter; left time: 106948.0732s\n",
            "\titers: 1900, epoch: 7 | loss: 0.0287017\n",
            "\tspeed: 0.1902s/iter; left time: 106358.0769s\n",
            "\titers: 2000, epoch: 7 | loss: 0.0197982\n",
            "\tspeed: 0.1876s/iter; left time: 104895.7669s\n",
            "\titers: 2100, epoch: 7 | loss: 0.0783169\n",
            "\tspeed: 0.1880s/iter; left time: 105117.9233s\n",
            "\titers: 2200, epoch: 7 | loss: 0.0312859\n",
            "\tspeed: 0.2043s/iter; left time: 114194.5185s\n",
            "\titers: 2300, epoch: 7 | loss: 0.0695426\n",
            "\tspeed: 0.1901s/iter; left time: 106223.9412s\n",
            "\titers: 2400, epoch: 7 | loss: 0.0330547\n",
            "\tspeed: 0.1885s/iter; left time: 105319.9464s\n",
            "\titers: 2500, epoch: 7 | loss: 0.0409838\n",
            "\tspeed: 0.1875s/iter; left time: 104772.3118s\n",
            "\titers: 2600, epoch: 7 | loss: 0.0193990\n",
            "\tspeed: 0.1881s/iter; left time: 105091.1318s\n",
            "\titers: 2700, epoch: 7 | loss: 0.0869312\n",
            "\tspeed: 0.1882s/iter; left time: 105133.5239s\n",
            "\titers: 2800, epoch: 7 | loss: 0.0362488\n",
            "\tspeed: 0.1897s/iter; left time: 105951.6014s\n",
            "\titers: 2900, epoch: 7 | loss: 0.0197767\n",
            "\tspeed: 0.1895s/iter; left time: 105799.1294s\n",
            "\titers: 3000, epoch: 7 | loss: 0.0298545\n",
            "\tspeed: 0.1871s/iter; left time: 104430.3581s\n",
            "\titers: 3100, epoch: 7 | loss: 0.0319862\n",
            "\tspeed: 0.1882s/iter; left time: 105018.5773s\n",
            "\titers: 3200, epoch: 7 | loss: 0.0391440\n",
            "\tspeed: 0.1897s/iter; left time: 105837.5271s\n",
            "\titers: 3300, epoch: 7 | loss: 0.1017943\n",
            "\tspeed: 0.1898s/iter; left time: 105862.5306s\n",
            "\titers: 3400, epoch: 7 | loss: 0.1522415\n",
            "\tspeed: 0.1888s/iter; left time: 105334.0534s\n",
            "\titers: 3500, epoch: 7 | loss: 0.0484673\n",
            "\tspeed: 0.1898s/iter; left time: 105852.2350s\n",
            "\titers: 3600, epoch: 7 | loss: 0.0290930\n",
            "\tspeed: 0.2047s/iter; left time: 114145.6114s\n",
            "\titers: 3700, epoch: 7 | loss: 0.0441633\n",
            "\tspeed: 0.1918s/iter; left time: 106921.2848s\n",
            "\titers: 3800, epoch: 7 | loss: 0.0296192\n",
            "\tspeed: 0.1913s/iter; left time: 106599.6850s\n",
            "\titers: 3900, epoch: 7 | loss: 0.0199261\n",
            "\tspeed: 0.1906s/iter; left time: 106233.2398s\n",
            "\titers: 4000, epoch: 7 | loss: 0.0482633\n",
            "\tspeed: 0.1900s/iter; left time: 105841.0456s\n",
            "\titers: 4100, epoch: 7 | loss: 0.0298406\n",
            "\tspeed: 0.1883s/iter; left time: 104884.9558s\n",
            "\titers: 4200, epoch: 7 | loss: 0.0593006\n",
            "\tspeed: 0.1897s/iter; left time: 105633.3066s\n",
            "\titers: 4300, epoch: 7 | loss: 0.0779235\n",
            "\tspeed: 0.1893s/iter; left time: 105442.2637s\n",
            "\titers: 4400, epoch: 7 | loss: 0.0221057\n",
            "\tspeed: 0.1923s/iter; left time: 107094.8681s\n",
            "\titers: 4500, epoch: 7 | loss: 0.0262926\n",
            "\tspeed: 0.1913s/iter; left time: 106494.6208s\n",
            "\titers: 4600, epoch: 7 | loss: 3.5447772\n",
            "\tspeed: 0.1888s/iter; left time: 105105.0775s\n",
            "\titers: 4700, epoch: 7 | loss: 0.0333742\n",
            "\tspeed: 0.1887s/iter; left time: 105000.4440s\n",
            "\titers: 4800, epoch: 7 | loss: 0.0879342\n",
            "\tspeed: 0.1922s/iter; left time: 106918.0057s\n",
            "\titers: 4900, epoch: 7 | loss: 0.0156025\n",
            "\tspeed: 0.1924s/iter; left time: 107025.3994s\n",
            "\titers: 5000, epoch: 7 | loss: 0.0153723\n",
            "\tspeed: 0.2064s/iter; left time: 114782.1910s\n",
            "\titers: 5100, epoch: 7 | loss: 0.0260550\n",
            "\tspeed: 0.1906s/iter; left time: 105979.3294s\n"
          ]
        }
      ],
      "source": [
        "args = Args('data', 'S', 720, 48, 48, 4, 1, 4, 0.0001, 8, 0.5, 'data_S_I720_O48_lr0.0001_bs8_dp0.5_h4_s1l3')\n",
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]\n",
        "\n",
        "init_model(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaweKjvpe0EuBd1psDSgMa",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}